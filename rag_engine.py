"""
rag_engine.py
Moteur RAG lÃ©ger basÃ© sur un corpus de connaissances statique.
Simule ChromaDB/LlamaIndex pour la dÃ©mo â€” structure prÃªte pour intÃ©gration rÃ©elle.
"""

import re
import unicodedata


# â”€â”€â”€ CORPUS DE CONNAISSANCES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CORPUS = {
    "dataset_311": {
        "titre": "RequÃªtes 311 â€“ Ville de MontrÃ©al",
        "description": "Le service 311 reÃ§oit les demandes citoyennes pour des problÃ¨mes urbains non-urgents. Chaque requÃªte contient : type de service, date, arrondissement, statut de traitement.",
        "categories": {
            "Nids-de-poule": "DÃ©gradations de la chaussÃ©e, typiquement post-gel/dÃ©gel (marsâ€“avril).",
            "DÃ©neigement": "Demandes liÃ©es au dÃ©blayage de neige, pics en dÃ©cembreâ€“fÃ©vrier.",
            "Ã‰clairage dÃ©fectueux": "Lampadaires, signaux ou zones mal Ã©clairÃ©es.",
            "Aqueduc/Fuite": "ProblÃ¨mes d'infrastructure hydraulique souterraine.",
            "Collecte des ordures": "Ramassage manquÃ© ou contenants endommagÃ©s.",
            "Entretien trottoir": "Trottoirs dÃ©gradÃ©s, craquelÃ©s ou dangereux.",
        },
        "source": "https://donnees.montreal.ca/dataset/requete-311"
    },
    "dataset_collisions": {
        "titre": "Collisions routiÃ¨res â€“ Ville de MontrÃ©al",
        "description": "DonnÃ©es gÃ©olocalisÃ©es des accidents de la route sur l'Ã®le de MontrÃ©al.",
        "champs": {
            "gravite": "Classification officielle : Dommages matÃ©riels â†’ BlessÃ©s lÃ©gers â†’ BlessÃ©s graves â†’ Mortel",
            "condition_meteo": "Condition atmosphÃ©rique au moment de l'accident.",
            "heure": "Heure de survenance (0â€“23). Pic habituel : 7hâ€“9h (matin) et 16hâ€“19h (soir).",
            "pietons": "Indique si des piÃ©tons sont impliquÃ©s.",
            "cyclistes": "Indique si des cyclistes sont impliquÃ©s.",
        },
        "source": "https://www.donneesquebec.ca/recherche/dataset/vmtl-collisions-routieres"
    },
    "dataset_stm": {
        "titre": "Transport collectif STM â€“ GTFS",
        "description": "DonnÃ©es du rÃ©seau de bus et mÃ©tro de la SociÃ©tÃ© de transport de MontrÃ©al.",
        "champs": {
            "stop_id": "Identifiant unique de l'arrÃªt.",
            "ligne": "NumÃ©ro ou nom de la ligne de bus/mÃ©tro.",
            "nb_passages_jour": "FrÃ©quence de passage quotidienne estimÃ©e.",
        },
        "source": "https://www.stm.info/fr/a-propos/developpeurs"
    },
    "dataset_meteo": {
        "titre": "MÃ©tÃ©o Canada â€“ API GeoMet OGC (climate-daily)",
        "description": (
            "Observations climatiques quotidiennes du Service mÃ©tÃ©orologique du Canada (SMC), "
            "accessibles via l'API GeoMet OGC standard (api.weather.gc.ca/collections/climate-daily). "
            "DonnÃ©es filtrÃ©es sur la bbox de l'Ã®le de MontrÃ©al (-74.0, 45.4, -73.4, 45.7). "
            "Champs disponibles : tempÃ©rature max/min (Â°C), prÃ©cipitations totales (mm), "
            "chutes de neige (cm), station mÃ©tÃ©o la plus proche."
        ),
        "champs": {
            "LOCAL_DATE":           "Date de l'observation (YYYY-MM-DD).",
            "MAX_TEMPERATURE":      "TempÃ©rature maximale du jour (Â°C).",
            "MIN_TEMPERATURE":      "TempÃ©rature minimale du jour (Â°C).",
            "TOTAL_PRECIPITATION":  "PrÃ©cipitations totales (mm) â€” pluie + neige fondue.",
            "TOTAL_SNOWFALL":       "Chutes de neige (cm).",
            "STATION_NAME":         "Nom de la station d'observation (ex: MONTREAL/TRUDEAU INTL A).",
        },
        "seuils_critiques": {
            "verglas":        "TempÃ©rature entre -5Â°C et 2Â°C + prÃ©cipitations > 0 â†’ risque de verglas.",
            "tempete_neige":  "TOTAL_SNOWFALL > 15cm en 24h â†’ tempÃªte de neige, impacts mobilitÃ© majeurs.",
            "pluie_forte":    "TOTAL_PRECIPITATION > 10mm â†’ chaussÃ©e glissante, visibilitÃ© rÃ©duite.",
            "grand_froid":    "MAX_TEMPERATURE < -15Â°C â†’ conditions extrÃªmes, hausse requÃªtes 311 dÃ©neigement.",
        },
        "endpoint": "https://api.weather.gc.ca/collections/climate-daily/items?bbox=-74.0,45.4,-73.4,45.7&f=json",
        "source": "https://api.weather.gc.ca/ (GeoMet-OGC-API, accÃ¨s public, sans clÃ©)"
    },
    "definitions": {
        "hotspot": "Zone gÃ©ographique prÃ©sentant une concentration anormalement Ã©levÃ©e d'incidents sur une pÃ©riode donnÃ©e.",
        "signal_faible": "Tendance Ã©mergente de faible volume mais persistante, pouvant annoncer un problÃ¨me futur.",
        "tendance": "Ã‰volution d'un indicateur dans le temps, comparÃ©e Ã  une pÃ©riode de rÃ©fÃ©rence (semaine/mois/annÃ©e prÃ©cÃ©dente).",
        "RAG": "Retrieval-Augmented Generation : approche qui ancre les rÃ©ponses du LLM sur un corpus de faits vÃ©rifiÃ©s pour Ã©viter les hallucinations.",
    }
}


class RAGEngine:
    """
    Moteur RAG lÃ©ger.
    RÃ©cupÃ¨re les chunks de connaissances pertinents selon la question.
    En production : ChromaDB + embeddings OpenAI/Claude.
    """
    
    def __init__(self):
        self.corpus = CORPUS
        self._build_index()
    
    def _build_index(self):
        """Construit un index simple par mots-clÃ©s."""
        self.index = {}
        keywords_map = {
            "311": ["dataset_311"],
            "requÃªte": ["dataset_311"],
            "nid": ["dataset_311"],
            "dÃ©neig": ["dataset_311"],
            "ordure": ["dataset_311"],
            "trottoir": ["dataset_311"],
            "collision": ["dataset_collisions"],
            "accident": ["dataset_collisions"],
            "gravitÃ©": ["dataset_collisions"],
            "piÃ©ton": ["dataset_collisions"],
            "cycliste": ["dataset_collisions"],
            "stm": ["dataset_stm"],
            "bus": ["dataset_stm"],
            "arrÃªt": ["dataset_stm"],
            "mÃ©tro": ["dataset_stm"],
            "mÃ©tÃ©o": ["dataset_meteo"],
            "pluie": ["dataset_meteo"],
            "neige": ["dataset_meteo"],
            "tempÃ©rature": ["dataset_meteo"],
            "verglas": ["dataset_meteo"],
            "hotspot": ["definitions"],
            "signal": ["definitions"],
            "tendance": ["definitions"],
        }
        for kw, sources in keywords_map.items():
            self.index[kw] = sources
    
    def retrieve(self, question: str, top_k: int = 3) -> list[dict]:
        """RÃ©cupÃ¨re les chunks pertinents pour une question."""
        question_lower = question.lower()
        relevant_sources = set()
        
        for kw, sources in self.index.items():
            if kw in question_lower:
                for s in sources:
                    relevant_sources.add(s)
        
        # Par dÃ©faut, inclure collisions + 311
        if not relevant_sources:
            relevant_sources = {"dataset_collisions", "dataset_311"}
        
        results = []
        for source_key in list(relevant_sources)[:top_k]:
            if source_key in self.corpus:
                results.append({
                    "source": source_key,
                    "content": self.corpus[source_key]
                })
        
        return results
    
    def get_glossary_context(self, question: str) -> str:
        """Retourne un contexte textuel formatÃ© pour le LLM."""
        chunks = self.retrieve(question)
        context_parts = []
        
        for chunk in chunks:
            content = chunk['content']
            titre = content.get('titre', chunk['source'])
            desc = content.get('description', '')
            context_parts.append(f"[SOURCE: {titre}]\n{desc}")
            
            if 'categories' in content:
                context_parts.append("CatÃ©gories: " + ", ".join(content['categories'].keys()))
            if 'seuils_critiques' in content:
                context_parts.append("Seuils critiques: " + str(content['seuils_critiques']))
        
        return "\n\n".join(context_parts)
    
    def detect_ambiguity(self, question: str) -> dict:
        """
        DÃ©tecte si une question est ambiguÃ«.
        Retourne {'is_ambiguous': bool, 'reason': str, 'clarifications': list}
        """
        question_lower = (question or "").lower()
        question_norm = unicodedata.normalize("NFKD", question_lower)
        question_norm = "".join(ch for ch in question_norm if not unicodedata.combining(ch))
        
        # Mots dÃ©clencheurs d'ambiguÃ¯tÃ©
        ambiguous_patterns = {
            "Ã§a coince": {
                "reason": "L'expression 'Ã§a coince' peut dÃ©signer plusieurs phÃ©nomÃ¨nes.",
                "clarifications": [
                    "ğŸš— Embouteillages / ralentissements de trafic",
                    "âš ï¸ Zones Ã  fort taux de collisions",
                    "ğŸ“‹ Secteurs avec beaucoup de requÃªtes 311 non rÃ©solues",
                ]
            },
            "Ã§a bloque": {
                "reason": "L'expression 'Ã§a bloque' peut dÃ©signer plusieurs phÃ©nomÃ¨nes.",
                "clarifications": [
                    "ğŸš— Embouteillages / ralentissements de trafic",
                    "âš ï¸ Zones Ã  fort taux de collisions",
                    "ğŸ“‹ Secteurs avec beaucoup de requÃªtes 311 non rÃ©solues",
                ]
            },
            "incidents": {
                "reason": "Le terme 'incidents' peut couvrir diffÃ©rents types de donnÃ©es.",
                "clarifications": [
                    "ğŸ’¥ Collisions routiÃ¨res (base de donnÃ©es accidents)",
                    "ğŸ“‹ RequÃªtes 311 (problÃ¨mes signalÃ©s par citoyens)",
                    "ğŸšŒ Perturbations du rÃ©seau STM",
                ]
            },
            "problÃ¨mes": {
                "reason": "Plusieurs types de problÃ¨mes sont disponibles dans les donnÃ©es.",
                "clarifications": [
                    "ğŸ›£ï¸ ProblÃ¨mes de voirie (nids-de-poule, trottoirs)",
                    "ğŸš¨ ProblÃ¨mes de sÃ©curitÃ© (collisions, zones dangereuses)",
                    "ğŸ’¡ ProblÃ¨mes d'infrastructure (Ã©clairage, aqueduc)",
                ]
            },
        }
        
        for pattern, info in ambiguous_patterns.items():
            pattern_norm = unicodedata.normalize("NFKD", pattern.lower())
            pattern_norm = "".join(ch for ch in pattern_norm if not unicodedata.combining(ch))
            if pattern in question_lower or pattern_norm in question_norm:
                return {
                    "is_ambiguous": True,
                    "reason": info["reason"],
                    "clarifications": info["clarifications"]
                }

        # Variantes frÃ©quentes non accentuÃ©es.
        if (
            re.search(r"\b(ca|Ã§a)\s+(coince|bloque)\b", question_lower)
            or re.search(r"\bou\s+ca\s+(coince|bloque)\b", question_norm)
        ):
            info = ambiguous_patterns["Ã§a coince"]
            return {
                "is_ambiguous": True,
                "reason": info["reason"],
                "clarifications": info["clarifications"],
            }
        
        return {"is_ambiguous": False}
